"""
æ¥­å‹™ãƒãƒ‹ãƒ¥ã‚¢ãƒ«è‡ªå‹•ç”Ÿæˆã‚¢ãƒ—ãƒª
å‹•ç”»ï¼ˆMP4ï¼‰ã¾ãŸã¯éŸ³å£°ï¼ˆMP3ï¼‰ã‹ã‚‰åˆ¤æ–­åŸºæº–ãŒå«ã¾ã‚Œã‚‹é«˜åº¦ãªæ¥­å‹™ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã‚’è‡ªå‹•ç”Ÿæˆ

ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£:
- éŸ³å£°èªè­˜: Groq Whisper API (large-v3) - é«˜ç²¾åº¦ãƒ»é«˜é€Ÿ
- ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ: Google Gemini API
- ãƒ›ã‚¹ãƒ†ã‚£ãƒ³ã‚°: Streamlit Cloudå¯¾å¿œ

Requirements (requirements.txt):
streamlit>=1.28.0
opencv-python-headless>=4.8.0
groq>=0.4.0
google-generativeai>=0.3.0
Pillow>=10.0.0
python-docx>=1.0.0
imageio-ffmpeg>=0.4.9
"""

import streamlit as st
import cv2
import tempfile
import os
import json
import base64
import zipfile
import io
import subprocess
import re
from datetime import timedelta
from PIL import Image
import numpy as np

# Wordå‡ºåŠ›ç”¨
try:
    from docx import Document
    from docx.shared import Inches, Pt, RGBColor
    from docx.enum.text import WD_ALIGN_PARAGRAPH
    from docx.enum.style import WD_STYLE_TYPE
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False

# ffmpegã®ãƒ‘ã‚¹ã‚’å–å¾—ã—ã¦PATHã«è¿½åŠ 
try:
    import imageio_ffmpeg
    FFMPEG_PATH = imageio_ffmpeg.get_ffmpeg_exe()
    ffmpeg_dir = os.path.dirname(FFMPEG_PATH)
    os.environ["PATH"] = ffmpeg_dir + os.pathsep + os.environ.get("PATH", "")
except ImportError:
    FFMPEG_PATH = "ffmpeg"

# Groq API (Whisper)
try:
    from groq import Groq
    GROQ_AVAILABLE = True
except ImportError:
    GROQ_AVAILABLE = False

# Google GenAI SDK (Gemini) - æ–°ã—ã„å…¬å¼SDK
try:
    from google import genai
    from google.genai import types
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False

# Supabase (ã‚¯ãƒ©ã‚¦ãƒ‰DB)
try:
    from supabase import create_client, Client
    SUPABASE_AVAILABLE = True
except ImportError:
    SUPABASE_AVAILABLE = False


# ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ¶é™ï¼ˆGroq API: 25MBï¼‰
MAX_CHUNK_SIZE_MB = 25
MAX_CHUNK_SIZE_BYTES = MAX_CHUNK_SIZE_MB * 1024 * 1024

# Gemini ãƒ¢ãƒ‡ãƒ«è¨­å®š
# æœ€é«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«: gemini-2.5-proï¼ˆ2025å¹´æœ€æ–°ï¼‰
GEMINI_MODEL_PRO = "gemini-2.5-pro"

# ============================================
# Supabase ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç®¡ç†
# ============================================

def get_supabase_client() -> Client:
    """Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—"""
    if not SUPABASE_AVAILABLE:
        return None

    # Streamlit secretsã¾ãŸã¯session_stateã‹ã‚‰URLã¨ã‚­ãƒ¼ã‚’å–å¾—
    supabase_url = None
    supabase_key = None

    # secretsã‹ã‚‰èª­ã¿è¾¼ã¿ï¼ˆã‚¨ãƒ©ãƒ¼ã‚’ç„¡è¦–ï¼‰
    try:
        supabase_url = st.secrets.get("SUPABASE_URL", "")
        supabase_key = st.secrets.get("SUPABASE_KEY", "")
    except Exception:
        pass

    # session_stateã‹ã‚‰èª­ã¿è¾¼ã¿ï¼ˆsecretsã‚ˆã‚Šå„ªå…ˆï¼‰
    if not supabase_url and "supabase_url" in st.session_state:
        supabase_url = st.session_state.supabase_url
    if not supabase_key and "supabase_key" in st.session_state:
        supabase_key = st.session_state.supabase_key

    if supabase_url and supabase_key:
        try:
            return create_client(supabase_url, supabase_key)
        except Exception:
            return None
    return None


# ============================================
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†æ©Ÿèƒ½ï¼ˆSupabaseå¯¾å¿œï¼‰
# ============================================

def get_project_list() -> list:
    """ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¸€è¦§ã‚’å–å¾—"""
    supabase = get_supabase_client()
    if not supabase:
        return []

    try:
        response = supabase.table("projects").select(
            "id, name, created_at, video_name"
        ).order("created_at", desc=True).execute()

        projects = []
        for row in response.data:
            projects.append({
                "id": row["id"],
                "name": row.get("name", "ç„¡é¡Œã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ"),
                "created_at": row.get("created_at", ""),
                "video_name": row.get("video_name", ""),
            })
        return projects
    except Exception as e:
        st.error(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¸€è¦§ã®å–å¾—ã«å¤±æ•—: {str(e)}")
        return []


def save_project(project_id: str, name: str, video_name: str, steps: list,
                 flow_summary: str, segments: list, video_duration: float):
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’Supabaseã«ä¿å­˜"""
    supabase = get_supabase_client()
    if not supabase:
        st.warning("SupabaseãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ä¿å­˜ã§ãã¾ã›ã‚“")
        return False

    # ç”»åƒã‚’Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦ä¿å­˜å¯èƒ½ãªå½¢å¼ã«å¤‰æ›
    steps_to_save = []
    for step in steps:
        step_copy = step.copy()
        if step_copy.get("image") is not None:
            try:
                pil_image = Image.fromarray(step_copy["image"])
                buffer = io.BytesIO()
                pil_image.save(buffer, format="PNG", optimize=True)
                step_copy["image_base64"] = base64.b64encode(buffer.getvalue()).decode()
            except:
                step_copy["image_base64"] = None
            del step_copy["image"]
        else:
            step_copy["image_base64"] = None
            if "image" in step_copy:
                del step_copy["image"]
        steps_to_save.append(step_copy)

    project_data = {
        "id": project_id,
        "name": name,
        "video_name": video_name,
        "flow_summary": flow_summary,
        "steps": steps_to_save,
        "segments": segments,
        "video_duration": video_duration,
    }

    try:
        # upsert: å­˜åœ¨ã™ã‚Œã°æ›´æ–°ã€ãªã‘ã‚Œã°æŒ¿å…¥
        supabase.table("projects").upsert(project_data).execute()
        return True
    except Exception as e:
        st.error(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ä¿å­˜ã«å¤±æ•—: {str(e)}")
        return False


def load_project(project_id: str) -> dict:
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’Supabaseã‹ã‚‰èª­ã¿è¾¼ã¿"""
    supabase = get_supabase_client()
    if not supabase:
        return None

    try:
        response = supabase.table("projects").select("*").eq("id", project_id).execute()

        if not response.data:
            return None

        data = response.data[0]

        # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒã‚’numpyé…åˆ—ã«æˆ»ã™
        steps = data.get("steps", [])
        for step in steps:
            if step.get("image_base64"):
                try:
                    img_data = base64.b64decode(step["image_base64"])
                    pil_image = Image.open(io.BytesIO(img_data))
                    step["image"] = np.array(pil_image)
                except:
                    step["image"] = None
            else:
                step["image"] = None
            if "image_base64" in step:
                del step["image_base64"]

        data["steps"] = steps
        return data
    except Exception as e:
        st.error(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {str(e)}")
        return None


def delete_project(project_id: str) -> bool:
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’Supabaseã‹ã‚‰å‰Šé™¤"""
    supabase = get_supabase_client()
    if not supabase:
        return False

    try:
        supabase.table("projects").delete().eq("id", project_id).execute()
        return True
    except Exception as e:
        st.error(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å‰Šé™¤ã«å¤±æ•—: {str(e)}")
        return False


def generate_project_id() -> str:
    """ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDã‚’ç”Ÿæˆ"""
    import uuid
    return str(uuid.uuid4())[:8]


def format_timestamp(seconds: float) -> str:
    """ç§’æ•°ã‚’MM:SSå½¢å¼ã«å¤‰æ›"""
    td = timedelta(seconds=int(seconds))
    minutes, secs = divmod(int(seconds), 60)
    return f"{minutes:02d}:{secs:02d}"


def get_file_size(file_path: str) -> int:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ãƒã‚¤ãƒˆã§å–å¾—"""
    return os.path.getsize(file_path)


def extract_audio_mp3(video_path: str, output_path: str) -> bool:
    """å‹•ç”»å…¨ä½“ã‹ã‚‰éŸ³å£°ã‚’mp3ã§ä¸€æ‹¬æŠ½å‡ºï¼ˆGroq APIå¯¾å¿œã€ä½ãƒ“ãƒƒãƒˆãƒ¬ãƒ¼ãƒˆã§åœ§ç¸®ï¼‰"""
    try:
        cmd = [
            FFMPEG_PATH, "-y",
            "-i", video_path,
            "-vn",
            "-acodec", "libmp3lame",
            "-ar", "16000",
            "-ac", "1",
            "-b:a", "48k",
            output_path
        ]
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode == 0 and os.path.exists(output_path):
            return True
        else:
            st.error(f"éŸ³å£°æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {result.stderr}")
            return False
    except Exception as e:
        st.error(f"éŸ³å£°æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}")
        return False


def split_audio_file(audio_path: str, max_size_bytes: int = MAX_CHUNK_SIZE_BYTES) -> list:
    """
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒ25MBã‚’è¶…ãˆã‚‹å ´åˆã®ã¿æ™‚é–“ã§åˆ†å‰²
    Returns: [(chunk_path, start_offset, is_temp), ...]
    """
    file_size = get_file_size(audio_path)

    if file_size <= max_size_bytes:
        return [(audio_path, 0, False)]

    # éŸ³å£°ã®é•·ã•ã‚’å–å¾—
    cmd = [FFMPEG_PATH, "-i", audio_path, "-f", "null", "-"]
    result = subprocess.run(cmd, capture_output=True, text=True)
    # ffmpegã®å‡ºåŠ›ã‹ã‚‰durationã‚’è§£æ
    duration = 0
    for line in result.stderr.split('\n'):
        if 'Duration' in line:
            time_str = line.split('Duration:')[1].split(',')[0].strip()
            parts = time_str.split(':')
            duration = float(parts[0]) * 3600 + float(parts[1]) * 60 + float(parts[2])
            break

    if duration == 0:
        return [(audio_path, 0, False)]

    # åˆ†å‰²æ•°ã‚’è¨ˆç®—
    num_chunks = int(np.ceil(file_size / max_size_bytes))
    chunk_duration = duration / num_chunks

    chunks = []
    temp_dir = tempfile.mkdtemp()

    for i in range(num_chunks):
        start_time = i * chunk_duration
        chunk_length = min(chunk_duration, duration - start_time)
        chunk_path = os.path.join(temp_dir, f"audio_chunk_{i}.mp3")

        cmd = [
            FFMPEG_PATH, "-y",
            "-ss", str(start_time),
            "-i", audio_path,
            "-t", str(chunk_length),
            "-acodec", "copy",
            chunk_path
        ]
        result = subprocess.run(cmd, capture_output=True, text=True)

        if result.returncode == 0 and os.path.exists(chunk_path):
            chunks.append((chunk_path, start_time, True))
        else:
            st.warning(f"éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ {i+1} ã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ")

    return chunks if chunks else [(audio_path, 0, False)]


def transcribe_full_video(video_path: str, groq_api_key: str,
                          whisper_model: str = "whisper-large-v3",
                          progress_callback=None, status_callback=None) -> list:
    """
    å‹•ç”»å…¨ä½“ã‹ã‚‰éŸ³å£°ã‚’ä¸€æ‹¬æŠ½å‡ºã—ã€Groq Whisper APIã§æ–‡å­—èµ·ã“ã—
    å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚µã‚¤ã‚ºã«é–¢ä¿‚ãªãã€éŸ³å£°ãƒ¬ãƒ™ãƒ«ã§æœ€é©ãªåˆ†å‰²ã‚’è¡Œã†
    """
    # Step 1: å‹•ç”»å…¨ä½“ã‹ã‚‰éŸ³å£°ã‚’mp3ã§ä¸€æ‹¬æŠ½å‡º
    if status_callback:
        status_callback("å‹•ç”»ã‹ã‚‰éŸ³å£°ã‚’æŠ½å‡ºä¸­...")
    if progress_callback:
        progress_callback(10)

    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp_audio:
        audio_path = tmp_audio.name

    if not extract_audio_mp3(video_path, audio_path):
        return []

    audio_size_mb = get_file_size(audio_path) / (1024 * 1024)
    if status_callback:
        status_callback(f"éŸ³å£°æŠ½å‡ºå®Œäº†ï¼ˆ{audio_size_mb:.1f}MBï¼‰")

    # Step 2: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒ25MBè¶…ã®å ´åˆã®ã¿åˆ†å‰²
    audio_chunks = split_audio_file(audio_path)
    num_chunks = len(audio_chunks)

    if num_chunks > 1 and status_callback:
        status_callback(f"éŸ³å£°ã‚’ {num_chunks} å€‹ã«åˆ†å‰²ã—ã¦å‡¦ç†ã—ã¾ã™...")

    # Step 3: å„éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’Groq APIã§æ–‡å­—èµ·ã“ã—
    all_segments = []
    for chunk_idx, (chunk_path, start_offset, is_temp) in enumerate(audio_chunks):
        if status_callback:
            if num_chunks > 1:
                status_callback(f"Groq Whisper APIã§éŸ³å£°èªè­˜ä¸­... ({chunk_idx + 1}/{num_chunks})")
            else:
                status_callback("Groq Whisper APIã§éŸ³å£°èªè­˜ä¸­...")

        if progress_callback:
            progress_callback(15 + int((chunk_idx / num_chunks) * 25))

        segments = transcribe_audio_with_groq(chunk_path, groq_api_key, whisper_model)

        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ã‚ªãƒ•ã‚»ãƒƒãƒˆèª¿æ•´
        for segment in segments:
            segment["start"] += start_offset
            segment["end"] += start_offset
            all_segments.append(segment)

        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        if is_temp:
            try:
                os.unlink(chunk_path)
            except:
                pass

    # å…ƒã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
    try:
        os.unlink(audio_path)
    except:
        pass

    return all_segments


def transcribe_audio_with_groq(audio_path: str, groq_api_key: str, model: str = "whisper-large-v3") -> list:
    """Groq Whisper APIã§éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãï¼‰"""
    if not GROQ_AVAILABLE:
        st.error("Groq SDKãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`pip install groq`ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return []

    try:
        client = Groq(api_key=groq_api_key)

        with open(audio_path, "rb") as audio_file:
            # verbose_jsonã§ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãã®çµæœã‚’å–å¾—
            transcription = client.audio.transcriptions.create(
                file=audio_file,
                model=model,
                response_format="verbose_json",
                language="ja",
                temperature=0.0
            )

        segments = []

        # verbose_jsonã®å ´åˆã€segmentsãŒå«ã¾ã‚Œã‚‹
        if hasattr(transcription, 'segments') and transcription.segments:
            for segment in transcription.segments:
                segments.append({
                    "start": segment.get("start", 0),
                    "end": segment.get("end", 0),
                    "text": segment.get("text", "")
                })
        elif hasattr(transcription, 'text'):
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒãªã„å ´åˆã¯å…¨ä½“ã‚’1ã¤ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨ã—ã¦æ‰±ã†
            segments.append({
                "start": 0,
                "end": 0,
                "text": transcription.text
            })

        return segments
    except Exception as e:
        st.error(f"GroqéŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return []


def transcribe_audio_file(audio_path: str, groq_api_key: str,
                          whisper_model: str = "whisper-large-v3",
                          progress_callback=None, status_callback=None) -> list:
    """
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆMP3ï¼‰ã‚’ç›´æ¥Groq Whisper APIã§æ–‡å­—èµ·ã“ã—
    å¿…è¦ã«å¿œã˜ã¦æœ€é©åŒ–ï¼ˆ16kHz ãƒ¢ãƒãƒ©ãƒ«åŒ–ï¼‰ã‚’è¡Œã†
    """
    if status_callback:
        status_callback("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æœ€é©åŒ–ä¸­...")
    if progress_callback:
        progress_callback(10)

    # éŸ³å£°ã‚’æœ€é©åŒ–ï¼ˆ16kHz ãƒ¢ãƒãƒ©ãƒ«ã€ä½ãƒ“ãƒƒãƒˆãƒ¬ãƒ¼ãƒˆï¼‰ã—ã¦ã‚µã‚¤ã‚ºã‚’å‰Šæ¸›
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp_audio:
        optimized_path = tmp_audio.name

    try:
        cmd = [
            FFMPEG_PATH, "-y",
            "-i", audio_path,
            "-vn",
            "-acodec", "libmp3lame",
            "-ar", "16000",
            "-ac", "1",
            "-b:a", "48k",
            optimized_path
        ]
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode != 0 or not os.path.exists(optimized_path):
            optimized_path = audio_path
    except Exception:
        optimized_path = audio_path

    audio_size_mb = get_file_size(optimized_path) / (1024 * 1024)
    if status_callback:
        status_callback(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ{audio_size_mb:.1f}MBï¼‰ã‚’å‡¦ç†ã—ã¾ã™")

    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒ25MBè¶…ã®å ´åˆã®ã¿åˆ†å‰²
    audio_chunks = split_audio_file(optimized_path)
    num_chunks = len(audio_chunks)

    if num_chunks > 1 and status_callback:
        status_callback(f"éŸ³å£°ã‚’ {num_chunks} å€‹ã«åˆ†å‰²ã—ã¦å‡¦ç†ã—ã¾ã™...")

    # å„éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’Groq APIã§æ–‡å­—èµ·ã“ã—
    all_segments = []
    for chunk_idx, (chunk_path, start_offset, is_temp) in enumerate(audio_chunks):
        if status_callback:
            if num_chunks > 1:
                status_callback(f"Groq Whisper APIã§éŸ³å£°èªè­˜ä¸­... ({chunk_idx + 1}/{num_chunks})")
            else:
                status_callback("Groq Whisper APIã§éŸ³å£°èªè­˜ä¸­...")

        if progress_callback:
            progress_callback(15 + int((chunk_idx / num_chunks) * 25))

        segments = transcribe_audio_with_groq(chunk_path, groq_api_key, whisper_model)

        for segment in segments:
            segment["start"] += start_offset
            segment["end"] += start_offset
            all_segments.append(segment)

        if is_temp:
            try:
                os.unlink(chunk_path)
            except:
                pass

    # æœ€é©åŒ–ã•ã‚ŒãŸä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
    if optimized_path != audio_path:
        try:
            os.unlink(optimized_path)
        except:
            pass

    return all_segments


def extract_frame(video_path: str, timestamp: float) -> np.ndarray:
    """æŒ‡å®šã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡º"""
    cap = cv2.VideoCapture(video_path)
    cap.set(cv2.CAP_PROP_POS_MSEC, timestamp * 1000)
    ret, frame = cap.read()
    cap.release()

    if ret:
        return cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    return None


def get_video_duration(video_path: str) -> float:
    """å‹•ç”»ã®é•·ã•ã‚’å–å¾—"""
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)
    cap.release()

    if fps > 0:
        return frame_count / fps
    return 0


def get_audio_duration(audio_path: str) -> float:
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®é•·ã•ã‚’å–å¾—ï¼ˆffmpegã‚’ä½¿ç”¨ï¼‰"""
    try:
        cmd = [FFMPEG_PATH, "-i", audio_path, "-f", "null", "-"]
        result = subprocess.run(cmd, capture_output=True, text=True)
        for line in result.stderr.split('\n'):
            if 'Duration' in line:
                time_str = line.split('Duration:')[1].split(',')[0].strip()
                parts = time_str.split(':')
                return float(parts[0]) * 3600 + float(parts[1]) * 60 + float(parts[2])
    except Exception:
        pass
    return 0


def build_full_transcript(segments: list) -> str:
    """
    Whisperã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‹ã‚‰ã€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãã®å…¨æ–‡ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ
    ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: [MM:SS-MM:SS] ãƒ†ã‚­ã‚¹ãƒˆ
    """
    lines = []
    for seg in segments:
        start_ts = format_timestamp(seg["start"])
        end_ts = format_timestamp(seg["end"])
        text = seg["text"].strip()
        if text:
            lines.append(f"[{start_ts}-{end_ts}] {text}")
    return "\n".join(lines)


def analyze_full_context_with_gemini(api_key: str, full_transcript: str) -> dict:
    """
    ã€Stage 1ã€‘ãƒ•ãƒ«ã‚³ãƒ³ãƒ†ã‚¯ã‚¹ãƒˆã‚’Gemini Proã«æ¸¡ã—ã¦ã€æ¥­å‹™ãƒ•ãƒ­ãƒ¼ã®æµã‚Œã¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³åˆ—ã‚’ç”Ÿæˆ

    Returns:
        {
            "flow_summary": "æ¥­å‹™å…¨ä½“ã®æµã‚Œã‚’æ•°æ–‡ã§èª¬æ˜ã—ãŸè¦ç´„",
            "actions": [
                {
                    "index": 1,
                    "action_title": "...",
                    "description": "...(å®Œçµã—ãŸæ–‡ç« )...",
                    "actor": "æ‹…å½“è€…åã‚„å½¹å‰²",
                    "screen": "ç”»é¢åã‚„ã‚·ã‚¹ãƒ†ãƒ å",
                    "object": "æ“ä½œå¯¾è±¡ç‰©",
                    "operation": "å…·ä½“çš„ãªæ“ä½œå†…å®¹",
                    "ai_hypothesis": "...",
                    "importance": "high" or "normal"
                },
                ...
            ]
        }

    â€» ã“ã®æ®µéšã§ã¯ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¯ä»˜ã‘ãªã„ï¼ˆãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®šç¾©ã®ã¿ï¼‰
    """
    if not GENAI_AVAILABLE:
        st.error("Google GenAI SDKãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`pip install google-genai`ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return None

    try:
        client = genai.Client(api_key=api_key)

        prompt = f"""
ã‚ãªãŸã¯æ¥­å‹™ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ä½œæˆã®å°‚é–€å®¶ã§ã™ã€‚

ä»¥ä¸‹ã¯ã€ã‚ã‚‹æ¥­å‹™æ“ä½œã‚’éŒ²ç”»ã—ãŸå‹•ç”»ã‹ã‚‰éŸ³å£°èªè­˜ï¼ˆWhisperï¼‰ã§å–å¾—ã—ãŸå…¨æ–‡ã®æ–‡å­—èµ·ã“ã—ã§ã™ã€‚
ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãã®ç™ºè©±ãƒ­ã‚°ã‚’èª­ã¿ã€**å‹•ç”»å…¨ä½“ã®ã‚³ãƒ³ãƒ†ã‚¯ã‚¹ãƒˆï¼ˆæµã‚Œãƒ»ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ï¼‰** ã‚’æŠŠæ¡ã—ãŸã†ãˆã§ã€
æ¥­å‹™ãƒ•ãƒ­ãƒ¼å…¨ä½“ã®è¦ç´„ã¨ã€ãã®ãƒ•ãƒ­ãƒ¼ã«æ²¿ã£ãŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆæ“ä½œï¼‰ã®ä¸€è¦§ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€é‡è¦ãªæŒ‡ç¤º - ã‚¢ã‚¯ã‚·ãƒ§ãƒ³åˆ†å‰²ã®ç²’åº¦ã€‘
1. ã¾ãšå‹•ç”»å…¨ä½“ã‚’é€šã—ã¦ã€Œã“ã®æ¥­å‹™ã¯ä½•ã‚’ã—ã¦ã„ã‚‹ã®ã‹ã€ã€Œã©ã‚“ãªæµã‚Œã§é€²ã‚“ã§ã„ã‚‹ã®ã‹ã€ã‚’ç†è§£ã—ã¦ãã ã•ã„ã€‚
2. **ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã¯å¯èƒ½ãªé™ã‚Šç´°ã‹ãåˆ†å‰²ã—ã¦ãã ã•ã„ã€‚**
   - 1ã¤ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ä¸­ã§ã€ã€Œç™»å ´äººç‰©ã€ã€Œå¯¾è±¡ç‰©ã€ã€Œæ“ä½œå†…å®¹ã€ã€Œç›®çš„ã€ãŒ1ã¤ã«çµã‚Šè¾¼ã‚ã‚‹ã¨ã“ã‚ã¾ã§ç´°ã‹ãåˆ†å‰²ã™ã‚‹ã“ã¨ã€‚
   - 1ã¤ã®èª¬æ˜æ–‡ã«è¤‡æ•°ã®æ“ä½œãŒæ··ã–ã£ã¦ã—ã¾ã†å ´åˆã¯ã€æ“ä½œã”ã¨ã«åˆ¥ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã¨ã—ã¦åˆ†å‰²ã™ã‚‹ã“ã¨ã€‚
3. **å„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã«ã¯ã€ä»¥ä¸‹ã®æƒ…å ±ã‚’å¯èƒ½ãªé™ã‚Šå…·ä½“çš„ã«å«ã‚ã¦ãã ã•ã„ï¼š**
   - èª°ãŒï¼ˆæ‹…å½“è€…ã€å½¹è·ã€éƒ¨ç½²ãªã©ï¼‰
   - ã„ã¤ï¼ˆã©ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ã€ã©ã®æ¡ä»¶ã§ï¼‰
   - ã©ã®ç”»é¢ã§ï¼ˆã‚·ã‚¹ãƒ†ãƒ åã€ç”»é¢åã€ã‚¿ãƒ–åãªã©ï¼‰
   - ã©ã®é …ç›®ã‚’ï¼ˆãƒœã‚¿ãƒ³åã€ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã€æ›¸é¡åãªã©ï¼‰
   - ã©ã†æ“ä½œã™ã‚‹ã‹ï¼ˆã‚¯ãƒªãƒƒã‚¯ã€å…¥åŠ›ã€ç¢ºèªã€åˆ†é¡ãªã©ï¼‰

ã€é‡è¦ãªæŒ‡ç¤º - å…¥åŠ›ãƒ»é¸æŠæ“ä½œã®è©³ç´°åŒ–ã€‘
**ç‰¹å®šã®ç”»é¢ã§ãƒ•ã‚©ãƒ¼ãƒ å…¥åŠ›ã‚„é¸æŠæ“ä½œã‚’è¡Œã£ã¦ã„ã‚‹å ´é¢ã§ã¯ã€ä»¥ä¸‹ã®ãƒ¬ãƒ™ãƒ«ã¾ã§è©³ç´°ã«èª¬æ˜ã—ã¦ãã ã•ã„ï¼š**
- ã€Œã©ã®ç”»é¢ã€ã®
- ã€Œã©ã®é …ç›®ï¼ˆãƒ©ãƒ™ãƒ«åãƒ»ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åï¼‰ã€ã«
- ã€Œã©ã‚“ãªå€¤ãƒ»æƒ…å ±ã€ã‚’
- ã€Œãªãœãã®ã‚ˆã†ã«å…¥åŠ›ï¼é¸æŠã—ã¦ã„ã‚‹ã®ã‹ã€

**å…¥åŠ›ãƒ»é¸æŠæ“ä½œã®èª¬æ˜ã®è‰¯ã„ä¾‹ï¼š**
- ã€Œ`å—ä»˜æ—¥` æ¬„ã«ã€ç”³è«‹æ›¸ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹å—ä»˜æ—¥ã‚’ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‹ã‚‰é¸æŠã—ã¦å…¥åŠ›ã—ã¾ã™ã€‚ã€
- ã€Œ`æ‹…å½“è€…` ãƒ—ãƒ«ãƒ€ã‚¦ãƒ³ã‹ã‚‰ã€è‡ªåˆ†ã®åå‰ã‚’é¸æŠã—ã¾ã™ã€‚ã€
- ã€Œ`ç”³è«‹ç•ªå·` ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ã€ç”³è«‹æ›¸å³ä¸Šã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹8æ¡ã®ç•ªå·ã‚’å…¥åŠ›ã—ã¾ã™ã€‚ã€
- ã€Œ`æ¤œç´¢` ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã€æ¡ä»¶ã«åˆè‡´ã™ã‚‹ç”³è«‹ã‚’ä¸€è¦§è¡¨ç¤ºã—ã¾ã™ã€‚ã€

**å…¥åŠ›ãƒ»é¸æŠæ“ä½œã®æ‚ªã„ä¾‹ï¼ˆã“ã®ãƒ¬ãƒ™ãƒ«ã¯é¿ã‘ã‚‹ã“ã¨ï¼‰ï¼š**
- ã€Œã“ã®ç”»é¢ã§æ¡ä»¶ã‚’è¨­å®šã—ã¦æ¤œç´¢ã—ã¾ã™ã€ï¼ˆâ†’ ã©ã®é …ç›®ã«ä½•ã‚’å…¥åŠ›ã™ã‚‹ã‹ä¸æ˜ï¼‰
- ã€Œå¿…è¦äº‹é …ã‚’å…¥åŠ›ã—ã¾ã™ã€ï¼ˆâ†’ å…·ä½“çš„ãªé …ç›®åã‚„å€¤ãŒä¸æ˜ï¼‰

**ãŸã ã—ã€UIã‹ã‚‰æ˜ç¢ºã«èª­ã¿å–ã‚Œãªã„é …ç›®åã‚„å€¤ã‚’ã€å‹æ‰‹ã«å‰µä½œã—ãªã„ã§ãã ã•ã„ã€‚**

ã€é‡è¦ãªæŒ‡ç¤º - é …ç›®åãƒ»ãƒªã‚¹ãƒˆã®å®Œå…¨åˆ—æŒ™ã€‘
**é¡§å®¢ã‹ã‚‰ç›´æ¥æŒ‡ç¤ºã•ã‚Œã¦ã„ã‚‹é …ç›®åãƒ»åˆ†é¡åãƒ»ãƒã‚§ãƒƒã‚¯é …ç›®ãªã©ãŒéŸ³å£°ã‚„ç”»é¢ã‹ã‚‰èª­ã¿å–ã‚Œã‚‹å ´åˆã¯ã€ãã‚Œã‚‰ã‚’çœç•¥ã›ãšã€ã™ã¹ã¦åˆ—æŒ™ã—ã¦ãã ã•ã„ã€‚**

- ã€Œãªã©ã€ã€Œã€œç­‰ã€ã€Œãã®ä»–ã€ã¨ã„ã£ãŸã¾ã¨ã‚è¡¨ç¾ã¯ä½¿ã‚ãšã€å®Ÿéš›ã®é …ç›®åã‚’ã™ã¹ã¦æ›¸ãå‡ºã™ã“ã¨ã€‚
- ä¾‹ãˆã°ï¼š
  - å¿…é ˆãƒã‚§ãƒƒã‚¯é …ç›®ã¨ã—ã¦ã€Œæ°åã€ã€Œä½æ‰€ã€ã€Œé›»è©±ç•ªå·ã€ã€Œç”Ÿå¹´æœˆæ—¥ã€ã€Œç”³è«‹æ—¥ã€ãŒè¨€åŠã•ã‚Œã¦ã„ã‚‹å ´åˆã€5ã¤ã™ã¹ã¦ã‚’åˆ—æŒ™ã™ã‚‹ã€‚
  - FAXé€ä¿¡å…ˆã¨ã—ã¦ã€Œç·å‹™èª²ã€ã€ŒçµŒç†èª²ã€ã€Œå–¶æ¥­éƒ¨ã€ãŒè¨€åŠã•ã‚Œã¦ã„ã‚‹å ´åˆã€3ã¤ã™ã¹ã¦ã‚’åˆ—æŒ™ã™ã‚‹ã€‚
- ç®‡æ¡æ›¸ãã§ã‚‚ã€1æ–‡ã®ä¸­ã«ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§ä¸¦ã¹ã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ãŒã€**é …ç›®ã‚’é£›ã°ã•ãªã„ã“ã¨**ã‚’æœ€å„ªå…ˆã—ã¦ãã ã•ã„ã€‚

ã€ç²’åº¦ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ï¼ˆå…·ä½“ä¾‹ï¼‰ã€‘
- FAXã®ä¾‹ï¼šã€Œã“ã®ç”»é¢ã§ã“ã®é …ç›®ã‚’ç¢ºèªã™ã‚‹ã€ã€Œã“ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ã“ã®æ‹…å½“è€…ãŒã€é»„è‰²ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã“ã®ç”³è«‹æ›¸ã‚’ç¶´ã˜ã‚‹ã€
- ã‚·ã‚¹ãƒ†ãƒ æ“ä½œã®ä¾‹ï¼šã€Œæ‹…å½“è€…AãŒå—ä»˜ç®¡ç†ç”»é¢ã®å½“æ—¥å—ä»˜ã‚¿ãƒ–ã‚’é–‹ãã€`ç”³è«‹ç•ªå·`ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ç”³è«‹æ›¸ã®ç•ªå·ã‚’å…¥åŠ›ã—ã¦`æ¤œç´¢`ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã€ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ç¢ºèªã™ã‚‹ã€
- æ›¸é¡å‡¦ç†ã®ä¾‹ï¼šã€Œçª“å£æ‹…å½“ãŒå—ä»˜å°ã‚’æŠ¼ã—ãŸç”³è«‹æ›¸ã‚’ã€ç”³è«‹ç¨®åˆ¥ã”ã¨ã«è‰²åˆ†ã‘ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆé’ï¼šæ–°è¦ã€é»„ï¼šå¤‰æ›´ã€èµ¤ï¼šå–æ¶ˆï¼‰ã«æ™‚ç³»åˆ—ã§ç¶´ã˜ã‚‹ã€

ã€é‡è¦ãªæŒ‡ç¤º - ä¸è¶³æƒ…å ±ã®æ˜ç¤ºã€‘
**ç”»é¢ã‚„éŸ³å£°ã‹ã‚‰ã€ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã‚„å…·ä½“çš„ãªå€¤ãŒèª­ã¿å–ã‚Œãªã„å ´åˆã¯ã€description ã«æ›–æ˜§ãªè¡¨ç¾ã‚’ã­ã˜è¾¼ã¾ãšã€ai_hypothesis ã«æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚**

ä¸è¶³æƒ…å ±ã®æ›¸ãæ–¹ã®ä¾‹ï¼š
- ã€Œã€æƒ…å ±ä¸è¶³ã€‘ã“ã®æ“ä½œã‚’è¡Œã†æ‹…å½“è€…ï¼ˆå½¹è·ãƒ»éƒ¨ç½²ï¼‰ãŒä¸æ˜ã§ã™ã€‚é¡§å®¢ã¸ã®ãƒ’ã‚¢ãƒªãƒ³ã‚°ãŒå¿…è¦ã§ã™ã€‚ã€
- ã€Œã€æƒ…å ±ä¸è¶³ã€‘`å—ä»˜æ—¥`ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ã©ã®å€¤ã‚’å…¥ã‚Œã‚‹ã‹ï¼ˆç”³è«‹æ›¸ã®æ—¥ä»˜ï¼Ÿå½“æ—¥ã®æ—¥ä»˜ï¼Ÿï¼‰ãŒä¸æ˜ã§ã™ã€‚ã€
- ã€Œã€æƒ…å ±ä¸è¶³ã€‘æ›¸é¡ã‚’ç¶´ã˜ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®è‰²ã‚„ç¨®é¡ãŒè¨€åŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã€
- ã€Œã€æƒ…å ±ä¸è¶³ã€‘æ¤œç´¢æ¡ä»¶ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹é …ç›®åãŒç‰¹å®šã§ãã¾ã›ã‚“ã€‚é¡§å®¢ã«ç¢ºèªãŒå¿…è¦ã§ã™ã€‚ã€
- ã€Œã€æƒ…å ±ä¸è¶³ã€‘ã“ã®åˆ¤æ–­ã®åŸºæº–ã¨ãªã‚‹é‡‘é¡ã‚„æ¡ä»¶ãŒæ˜ç¤ºã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ä¾‹ï¼šâ—¯å††ä»¥ä¸Šã®å ´åˆãªã©ã€‚ã€

ã€å…¥åŠ›ï¼ˆå…¨æ–‡æ–‡å­—èµ·ã“ã—ï¼‰ã€‘
{full_transcript}

ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆå¿…ãšã“ã®JSONã ã‘ã‚’è¿”ã™ã“ã¨ï¼‰ã€‘
{{
  "flow_summary": "æ¥­å‹™å…¨ä½“ã®æµã‚Œã‚’2ã€œ4æ–‡ã§èª¬æ˜ã—ãŸè¦ç´„ã€‚ã“ã®æ¥­å‹™ãŒä½•ã‚’é”æˆã—ã‚ˆã†ã¨ã—ã¦ã„ã‚‹ã‹ã€ã©ã‚“ãªã‚¹ãƒ†ãƒƒãƒ—ã‚’çµŒã‚‹ã‹ã‚’ç°¡æ½”ã«èª¬æ˜ã™ã‚‹ã€‚",
  "actions": [
    {{
      "index": 1,
      "action_title": "ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆä¾‹ï¼šå—ä»˜ç®¡ç†ç”»é¢ã§ç”³è«‹æ›¸ã‚’æ¤œç´¢ã™ã‚‹ï¼‰",
      "description": "ã“ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ç›®çš„ã€å…·ä½“çš„ãªæ“ä½œã€æ“ä½œå¾Œã«ä½•ãŒèµ·ãã‚‹ã‹ã‚’å«ã‚€å®Œçµã—ãŸèª¬æ˜æ–‡ã€‚`ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å`ã‚„`ãƒœã‚¿ãƒ³å`ã‚’æ˜è¨˜ã—ã€èª°ãŒãƒ»ã©ã®ç”»é¢ã§ãƒ»ä½•ã‚’ãƒ»ã©ã†æ“ä½œã™ã‚‹ã‹ã‚’å…·ä½“çš„ã«æ›¸ãã€‚",
      "actor": "ã“ã®æ“ä½œã‚’è¡Œã†æ‹…å½“è€…ãƒ»å½¹è·ãƒ»éƒ¨ç½²ï¼ˆä¸æ˜ãªå ´åˆã¯ç©ºæ–‡å­—ï¼‰",
      "screen": "æ“ä½œã™ã‚‹ç”»é¢åãƒ»ã‚·ã‚¹ãƒ†ãƒ åãƒ»ã‚¿ãƒ–åï¼ˆä¸æ˜ãªå ´åˆã¯ç©ºæ–‡å­—ï¼‰",
      "object": "æ“ä½œå¯¾è±¡ã¨ãªã‚‹æ›¸é¡ãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ»é …ç›®ï¼ˆä¸æ˜ãªå ´åˆã¯ç©ºæ–‡å­—ï¼‰",
      "operation": "å…·ä½“çš„ãªæ“ä½œå†…å®¹ï¼ˆã‚¯ãƒªãƒƒã‚¯ã€å…¥åŠ›ã€ç¢ºèªã€åˆ†é¡ãªã©ï¼‰",
      "ai_hypothesis": "ã€è¦ç¢ºèªã€‘ã‚„ã€æƒ…å ±ä¸è¶³ã€‘ã¨ã—ã¦ã€ç¢ºèªãŒå¿…è¦ãªäº‹é …ã‚„ä¸æ˜ç‚¹ã‚’è³ªå•å½¢å¼ã§è¨˜è¼‰ã€‚æƒ…å ±ãŒååˆ†ãªå ´åˆã¯ç©ºæ–‡å­—ã€‚",
      "importance": "high" ã¾ãŸã¯ "normal"ï¼ˆé‡è¦ãªåˆ¤æ–­ãƒã‚¤ãƒ³ãƒˆãƒ»ãƒªã‚¹ã‚¯ãŒã‚ã‚‹æ“ä½œãªã‚‰ highï¼‰
    }}
  ]
}}

æ³¨æ„:
- å¿…ãšJSONå½¢å¼ã®ã¿ã‚’è¿”ã—ã€ä½™è¨ˆãªæ–‡ç« ã‚„èª¬æ˜ã¯ä¸€åˆ‡ä»˜ã‘ãªã„ã§ãã ã•ã„ã€‚
- actionsé…åˆ—ã®å„è¦ç´ ã«ã¯indexã‚’1ã‹ã‚‰é †ç•ªã«æŒ¯ã£ã¦ãã ã•ã„ã€‚
- **ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¯ã“ã®æ®µéšã§ã¯ä¸è¦ã§ã™ã€‚** ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®å†…å®¹ã ã‘ã«é›†ä¸­ã—ã¦ãã ã•ã„ã€‚
- descriptionã¯ã€Œã€œã—ã¾ã™ã€ã€Œã€œã‚’ç¢ºèªã—ã¾ã™ã€ã®ã‚ˆã†ãªä¸å¯§ãªæ–‡ä½“ã§è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
- **ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®æ•°ãŒå¤šããªã£ã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚ç´°ã‹ãåˆ†å‰²ã™ã‚‹ã“ã¨ã‚’å„ªå…ˆã—ã¦ãã ã•ã„ã€‚**
- **å…¥åŠ›ãƒ»é¸æŠæ“ä½œã§ã¯ã€`ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å`ã¨å…¥åŠ›ã™ã‚‹å€¤ã‚’å…·ä½“çš„ã«è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚**
- **é …ç›®åã‚„ãƒªã‚¹ãƒˆã¯ã€Œãªã©ã€ã€Œç­‰ã€ã§çœç•¥ã›ãšã€ã™ã¹ã¦åˆ—æŒ™ã—ã¦ãã ã•ã„ã€‚**
- æƒ…å ±ãŒã‚ã‚‹éƒ¨åˆ†ã¯å¯èƒ½ãªé™ã‚Šå…·ä½“çš„ã«ã€æƒ…å ±ãŒãªã„éƒ¨åˆ†ã¯ã€Œã€æƒ…å ±ä¸è¶³ã€‘ã€ã¨ã—ã¦è¦‹ãˆã‚‹åŒ–ã—ã¦ãã ã•ã„ã€‚
"""

        response = client.models.generate_content(
            model=GEMINI_MODEL_PRO,
            contents=prompt,
        )
        response_text = response.text.strip()

        # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯å¯¾ç­–
        if "```json" in response_text:
            response_text = response_text.split("```json")[1].split("```")[0]
        elif "```" in response_text:
            response_text = response_text.split("```")[1].split("```")[0]

        result = json.loads(response_text)
        return result

    except json.JSONDecodeError as e:
        st.warning(f"Geminiå¿œç­”ã®JSONãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return None
    except Exception as e:
        st.error(f"Gemini API ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None


def calculate_text_similarity(text1: str, text2: str) -> float:
    """
    2ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆé–“ã®ç°¡æ˜“çš„ãªé¡ä¼¼åº¦ã‚’è¨ˆç®—ï¼ˆå˜èªã®é‡è¤‡ç‡ï¼‰
    """
    # æ—¥æœ¬èªç”¨ï¼šæ–‡å­—å˜ä½ã§n-gramã‚’ä½œæˆ
    def get_ngrams(text, n=2):
        text = text.lower().strip()
        # å¥èª­ç‚¹ã‚„è¨˜å·ã‚’é™¤å»
        text = re.sub(r'[ã€ã€‚ï¼ï¼Ÿ\s\[\]\-:ï¼š]', '', text)
        return set(text[i:i+n] for i in range(len(text) - n + 1)) if len(text) >= n else {text}

    ngrams1 = get_ngrams(text1)
    ngrams2 = get_ngrams(text2)

    if not ngrams1 or not ngrams2:
        return 0.0

    intersection = ngrams1 & ngrams2
    union = ngrams1 | ngrams2

    return len(intersection) / len(union) if union else 0.0


def map_actions_to_segments(actions: list, segments: list) -> list:
    """
    ã€Stage 2ã€‘ã‚¢ã‚¯ã‚·ãƒ§ãƒ³åˆ—ã‚’ã‚»ã‚°ãƒ¡ãƒ³ãƒˆç¾¤ã«ãƒãƒƒãƒ”ãƒ³ã‚°ã—ã¦ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ä»˜ä¸

    å„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã«å¯¾ã—ã¦ã€æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’è¦‹ã¤ã‘ã€
    ãã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®æ™‚é–“ç¯„å›²ã‚’ä½¿ã£ã¦ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’è¨­å®šã™ã‚‹ã€‚

    ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯:
    1. ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®descriptionã¨action_titleã‹ã‚‰é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
    2. å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—
    3. æœ€ã‚‚é¡ä¼¼åº¦ãŒé«˜ã„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆç¾¤ã‚’ç‰¹å®š
    4. ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®é †åºã‚’ä¿ã¡ãªãŒã‚‰ã€æ™‚é–“çš„ã«å‰é€²ã™ã‚‹ã‚ˆã†ã«ãƒãƒƒãƒ”ãƒ³ã‚°
    """
    if not segments:
        return actions

    mapped_actions = []
    last_used_segment_idx = -1
    total_duration = segments[-1]["end"] if segments else 0

    # å„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã«å‡ç­‰ã«æ™‚é–“ã‚’å‰²ã‚Šå½“ã¦ã‚‹ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
    time_per_action = total_duration / len(actions) if actions else 0

    for action_idx, action in enumerate(actions):
        action_text = f"{action.get('action_title', '')} {action.get('description', '')}"

        best_segment_idx = -1
        best_score = -1

        # å‰ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚ˆã‚Šå¾Œã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ã¿ã‚’æ¤œç´¢ï¼ˆé †åºã‚’ä¿ã¤ï¼‰
        search_start = max(0, last_used_segment_idx)

        for seg_idx in range(search_start, len(segments)):
            seg = segments[seg_idx]
            seg_text = seg.get("text", "")

            score = calculate_text_similarity(action_text, seg_text)

            # æ™‚é–“çš„ãªä½ç½®ã«ã‚ˆã‚‹é‡ã¿ä»˜ã‘ï¼ˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®é †åºã«è¿‘ã„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å„ªå…ˆï¼‰
            expected_time = action_idx * time_per_action
            seg_mid_time = (seg["start"] + seg["end"]) / 2
            time_distance = abs(seg_mid_time - expected_time)
            time_weight = 1.0 / (1.0 + time_distance / total_duration * 2) if total_duration > 0 else 1.0

            weighted_score = score * 0.7 + time_weight * 0.3

            if weighted_score > best_score:
                best_score = weighted_score
                best_segment_idx = seg_idx

        # ãƒãƒƒãƒã™ã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€å‡ç­‰å‰²ã‚Šå½“ã¦ã‚’ä½¿ç”¨
        if best_segment_idx < 0:
            start_sec = action_idx * time_per_action
            end_sec = (action_idx + 1) * time_per_action
        else:
            # è¦‹ã¤ã‹ã£ãŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨ãã®å‘¨è¾ºã‚’ä½¿ç”¨
            matched_seg = segments[best_segment_idx]

            # å‰å¾Œã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚‚å«ã‚ã¦æ™‚é–“ç¯„å›²ã‚’æ‹¡å¼µï¼ˆåŒã˜ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã«é–¢é€£ã™ã‚‹å¯èƒ½æ€§ï¼‰
            start_seg_idx = best_segment_idx
            end_seg_idx = best_segment_idx

            # é¡ä¼¼åº¦ãŒä¸€å®šä»¥ä¸Šã®éš£æ¥ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å«ã‚ã‚‹
            threshold = best_score * 0.5 if best_score > 0 else 0

            # å‰æ–¹ã‚’ç¢ºèª
            for i in range(best_segment_idx - 1, max(last_used_segment_idx, -1), -1):
                seg_text = segments[i].get("text", "")
                if calculate_text_similarity(action_text, seg_text) >= threshold:
                    start_seg_idx = i
                else:
                    break

            # å¾Œæ–¹ã‚’ç¢ºèªï¼ˆæ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã¨ã®é‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚ã€æ§ãˆã‚ã«ï¼‰
            for i in range(best_segment_idx + 1, min(best_segment_idx + 3, len(segments))):
                seg_text = segments[i].get("text", "")
                if calculate_text_similarity(action_text, seg_text) >= threshold:
                    end_seg_idx = i
                else:
                    break

            start_sec = segments[start_seg_idx]["start"]
            end_sec = segments[end_seg_idx]["end"]
            last_used_segment_idx = end_seg_idx

        # ãƒãƒƒãƒ”ãƒ³ã‚°çµæœã‚’ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã«è¿½åŠ 
        mid_sec = (start_sec + end_sec) / 2

        mapped_action = {
            "index": action.get("index", action_idx + 1),
            "action_title": action.get("action_title", f"æ‰‹é † {action_idx + 1}"),
            "description": action.get("description", ""),
            "actor": action.get("actor", ""),
            "screen": action.get("screen", ""),
            "object": action.get("object", ""),
            "operation": action.get("operation", ""),
            "ai_hypothesis": action.get("ai_hypothesis", ""),
            "importance": action.get("importance", "normal"),
            "is_important": action.get("importance") == "high",
            "start_sec": start_sec,
            "end_sec": end_sec,
            "timestamp_seconds": mid_sec,
            "timestamp": format_timestamp(mid_sec),
            "image": None,  # å¾Œã§ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’å–å¾—
        }

        mapped_actions.append(mapped_action)

    return mapped_actions


def extract_screenshots_for_actions(video_path: str, actions: list) -> list:
    """
    ãƒãƒƒãƒ”ãƒ³ã‚°æ¸ˆã¿ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³åˆ—ã«å¯¾ã—ã¦ã€ä»£è¡¨ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’å–å¾—
    """
    for action in actions:
        mid_sec = action.get("timestamp_seconds", 0)
        frame = extract_frame(video_path, mid_sec)
        action["image"] = frame

    return actions


def process_video_chunk(chunk_path: str, start_offset: float, groq_api_key: str,
                        whisper_model: str = "whisper-large-v3",
                        progress_callback=None) -> list:
    """
    å‹•ç”»ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†ã—ã¦ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’è¿”ã™ï¼ˆGroq Whisper APIã§éŸ³å£°èªè­˜ï¼‰
    Returns: segments
    """
    all_segments = []

    # éŸ³å£°æŠ½å‡ºï¼ˆmp3å½¢å¼ã§å‡ºåŠ› - Groq APIã«å¯¾å¿œï¼‰
    if progress_callback:
        progress_callback("éŸ³å£°ã‚’æŠ½å‡ºä¸­...")

    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp_audio:
        audio_path = tmp_audio.name

    # mp3å½¢å¼ã§éŸ³å£°æŠ½å‡ºï¼ˆGroq APIå¯¾å¿œã®ãŸã‚ï¼‰
    try:
        cmd = [
            FFMPEG_PATH, "-y",
            "-i", chunk_path,
            "-vn",
            "-acodec", "libmp3lame",
            "-ar", "16000",
            "-ac", "1",
            "-b:a", "64k",
            audio_path
        ]
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode != 0:
            st.error(f"éŸ³å£°æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {result.stderr}")
            return []
    except Exception as e:
        st.error(f"éŸ³å£°æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}")
        return []

    # Groq Whisper APIã§éŸ³å£°èªè­˜
    if progress_callback:
        progress_callback("Groq Whisper APIã§éŸ³å£°èªè­˜ä¸­...")

    segments = transcribe_audio_with_groq(audio_path, groq_api_key, whisper_model)

    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ã‚ªãƒ•ã‚»ãƒƒãƒˆèª¿æ•´
    for segment in segments:
        segment["start"] += start_offset
        segment["end"] += start_offset
        all_segments.append(segment)

    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    try:
        os.unlink(audio_path)
    except:
        pass

    return all_segments


def generate_fallback_steps(segments: list, video_path: str) -> list:
    """
    Geminiè§£æãŒå¤±æ•—ã—ãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šã‚»ã‚°ãƒ¡ãƒ³ãƒˆå˜ä½ã§ç°¡æ˜“ã‚¹ãƒ†ãƒƒãƒ—ã‚’ç”Ÿæˆ
    """
    steps = []
    for i, seg in enumerate(segments):
        mid_sec = (seg["start"] + seg["end"]) / 2.0
        frame = extract_frame(video_path, mid_sec)
        steps.append({
            "index": i + 1,
            "start_sec": seg["start"],
            "end_sec": seg["end"],
            "timestamp_seconds": mid_sec,
            "timestamp": format_timestamp(mid_sec),
            "action_title": f"æ‰‹é † {i+1}",
            "description": seg.get("text", "ï¼ˆèª¬æ˜ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼‰"),
            "actor": "",
            "screen": "",
            "object": "",
            "operation": "",
            "ai_hypothesis": "",
            "importance": "normal",
            "is_important": False,
            "image": frame,
        })
    return steps


def generate_markdown(steps: list, flow_summary: str = None) -> tuple:
    """Markdownå½¢å¼ã®ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã¨ç”»åƒã‚’ç”Ÿæˆ"""
    markdown_lines = ["# æ¥­å‹™ãƒãƒ‹ãƒ¥ã‚¢ãƒ«\n"]

    # ãƒ•ãƒ­ãƒ¼æ¦‚è¦ãŒã‚ã‚Œã°è¿½åŠ 
    if flow_summary:
        markdown_lines.append("## æ¦‚è¦\n")
        markdown_lines.append(f"{flow_summary}\n")
        markdown_lines.append("\n---\n")

    markdown_lines.append("## æ‰‹é †\n")

    images = {}
    img_counter = 1

    for i, step in enumerate(steps):
        if step.get("deleted", False):
            continue

        markdown_lines.append(f"### {step.get('index', i+1)}. {step['action_title']}\n")
        markdown_lines.append(f"**ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—:** {step['timestamp']}\n")

        if step.get("image") is not None:
            img_filename = f"img_{img_counter}.png"
            images[img_filename] = step["image"]
            markdown_lines.append(f"![æ‰‹é †{step.get('index', i+1)}ã®ç”»åƒ](./{img_filename})\n")
            img_counter += 1

        # è©³ç´°æƒ…å ±ï¼ˆactor, screen, object, operationï¼‰ãŒã‚ã‚Œã°è¡¨ç¤º
        details = []
        if step.get("actor"):
            details.append(f"**æ‹…å½“:** {step['actor']}")
        if step.get("screen"):
            details.append(f"**ç”»é¢:** {step['screen']}")
        if step.get("object"):
            details.append(f"**å¯¾è±¡:** {step['object']}")
        if step.get("operation"):
            details.append(f"**æ“ä½œ:** {step['operation']}")

        if details:
            markdown_lines.append("\n" + " | ".join(details) + "\n")

        markdown_lines.append(f"\n{step['description']}\n")

        if step.get("ai_hypothesis") and not step.get("hypothesis_resolved", False):
            # ã€æƒ…å ±ä¸è¶³ã€‘ã‚„ã€è¦ç¢ºèªã€‘ã‚’å¼·èª¿è¡¨ç¤º
            hypothesis = step['ai_hypothesis']
            if "ã€æƒ…å ±ä¸è¶³ã€‘" in hypothesis:
                markdown_lines.append(f"\n> **[æƒ…å ±ä¸è¶³]** {hypothesis.replace('ã€æƒ…å ±ä¸è¶³ã€‘', '')}\n")
            elif "ã€è¦ç¢ºèªã€‘" in hypothesis:
                markdown_lines.append(f"\n> **[è¦ç¢ºèª]** {hypothesis.replace('ã€è¦ç¢ºèªã€‘', '')}\n")
            else:
                markdown_lines.append(f"\n> **AIç¢ºèªäº‹é …:** {hypothesis}\n")

        if step.get("is_important") or step.get("importance") == "high":
            markdown_lines.append("\n**[é‡è¦ãƒã‚¤ãƒ³ãƒˆ]**\n")

        markdown_lines.append("\n---\n")

    return "\n".join(markdown_lines), images


def create_download_zip(markdown: str, images: dict) -> bytes:
    """Markdownã¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ZIPåœ§ç¸®"""
    buffer = io.BytesIO()

    with zipfile.ZipFile(buffer, "w", zipfile.ZIP_DEFLATED) as zf:
        zf.writestr("manual.md", markdown)

        for filename, image in images.items():
            img_buffer = io.BytesIO()
            pil_image = Image.fromarray(image)
            pil_image.save(img_buffer, format="PNG")
            zf.writestr(filename, img_buffer.getvalue())

    buffer.seek(0)
    return buffer.getvalue()


def generate_word_document(steps: list, flow_summary: str = None) -> bytes:
    """Wordå½¢å¼ï¼ˆ.docxï¼‰ã®ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã‚’ç”Ÿæˆ"""
    if not DOCX_AVAILABLE:
        return None

    doc = Document()

    # ã‚¿ã‚¤ãƒˆãƒ«
    title = doc.add_heading('æ¥­å‹™ãƒãƒ‹ãƒ¥ã‚¢ãƒ«', 0)
    title.alignment = WD_ALIGN_PARAGRAPH.CENTER

    # ãƒ•ãƒ­ãƒ¼æ¦‚è¦
    if flow_summary:
        doc.add_heading('æ¦‚è¦', level=1)
        doc.add_paragraph(flow_summary)
        doc.add_paragraph()  # ç©ºè¡Œ

    # æ‰‹é †
    doc.add_heading('æ‰‹é †', level=1)

    for i, step in enumerate(steps):
        if step.get("deleted", False):
            continue

        # æ‰‹é †ã‚¿ã‚¤ãƒˆãƒ«
        step_index = step.get('index', i+1)
        importance_mark = "[é‡è¦] " if step.get("is_important") or step.get("importance") == "high" else ""
        heading = doc.add_heading(f'{importance_mark}{step_index}. {step["action_title"]}', level=2)

        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
        ts_para = doc.add_paragraph()
        ts_run = ts_para.add_run(f'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: {step["timestamp"]}')
        ts_run.bold = True
        ts_run.font.size = Pt(10)
        ts_run.font.color.rgb = RGBColor(100, 100, 100)

        # ç”»åƒã‚’æŒ¿å…¥
        if step.get("image") is not None:
            try:
                # numpyé…åˆ—ã‚’PILç”»åƒã«å¤‰æ›ã—ã¦ãƒã‚¤ãƒˆã‚¹ãƒˆãƒªãƒ¼ãƒ ã«ä¿å­˜
                pil_image = Image.fromarray(step["image"])
                img_buffer = io.BytesIO()
                pil_image.save(img_buffer, format="PNG")
                img_buffer.seek(0)

                # Wordæ–‡æ›¸ã«ç”»åƒã‚’è¿½åŠ ï¼ˆå¹…ã‚’æŒ‡å®šï¼‰
                doc.add_picture(img_buffer, width=Inches(5.5))

                # ç”»åƒã‚’ä¸­å¤®å¯„ã›
                last_paragraph = doc.paragraphs[-1]
                last_paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            except Exception as e:
                doc.add_paragraph(f"[ç”»åƒã®æŒ¿å…¥ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}]")

        # è©³ç´°æƒ…å ±ï¼ˆactor, screen, object, operationï¼‰
        details = []
        if step.get("actor"):
            details.append(f"æ‹…å½“: {step['actor']}")
        if step.get("screen"):
            details.append(f"ç”»é¢: {step['screen']}")
        if step.get("object"):
            details.append(f"å¯¾è±¡: {step['object']}")
        if step.get("operation"):
            details.append(f"æ“ä½œ: {step['operation']}")

        if details:
            detail_para = doc.add_paragraph()
            for j, detail in enumerate(details):
                if j > 0:
                    detail_para.add_run("  |  ")
                run = detail_para.add_run(detail)
                run.font.size = Pt(9)
                run.font.color.rgb = RGBColor(80, 80, 80)

        # èª¬æ˜æ–‡
        doc.add_paragraph(step['description'])

        # AIä»®èª¬ãƒ»æƒ…å ±ä¸è¶³
        if step.get("ai_hypothesis") and not step.get("hypothesis_resolved", False):
            hypothesis = step['ai_hypothesis']
            hypo_para = doc.add_paragraph()

            if "ã€æƒ…å ±ä¸è¶³ã€‘" in hypothesis:
                run = hypo_para.add_run("[æƒ…å ±ä¸è¶³] ")
                run.bold = True
                run.font.color.rgb = RGBColor(200, 0, 0)  # èµ¤è‰²
                hypo_para.add_run(hypothesis.replace('ã€æƒ…å ±ä¸è¶³ã€‘', ''))
            elif "ã€è¦ç¢ºèªã€‘" in hypothesis:
                run = hypo_para.add_run("[è¦ç¢ºèª] ")
                run.bold = True
                run.font.color.rgb = RGBColor(200, 150, 0)  # ã‚ªãƒ¬ãƒ³ã‚¸è‰²
                hypo_para.add_run(hypothesis.replace('ã€è¦ç¢ºèªã€‘', ''))
            else:
                run = hypo_para.add_run("AIç¢ºèªäº‹é …: ")
                run.bold = True
                hypo_para.add_run(hypothesis)

        # é‡è¦ãƒã‚¤ãƒ³ãƒˆãƒãƒ¼ã‚¯
        if step.get("is_important") or step.get("importance") == "high":
            important_para = doc.add_paragraph()
            run = important_para.add_run("[é‡è¦ãƒã‚¤ãƒ³ãƒˆ]")
            run.bold = True
            run.font.color.rgb = RGBColor(200, 0, 0)

        # åŒºåˆ‡ã‚Šç·šä»£ã‚ã‚Šã®ç©ºè¡Œ
        doc.add_paragraph()
        doc.add_paragraph("â”€" * 50)
        doc.add_paragraph()

    # ãƒã‚¤ãƒˆã‚¹ãƒˆãƒªãƒ¼ãƒ ã¨ã—ã¦å‡ºåŠ›
    buffer = io.BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer.getvalue()


def main():
    st.set_page_config(
        page_title="æ¥­å‹™ãƒãƒ‹ãƒ¥ã‚¢ãƒ«è‡ªå‹•ç”Ÿæˆ",
        page_icon="ğŸ“‹",
        layout="wide"
    )

    # Session StateåˆæœŸåŒ–
    if "steps" not in st.session_state:
        st.session_state.steps = []
    if "flow_summary" not in st.session_state:
        st.session_state.flow_summary = None
    if "video_path" not in st.session_state:
        st.session_state.video_path = None
    if "video_duration" not in st.session_state:
        st.session_state.video_duration = 0
    if "segments" not in st.session_state:
        st.session_state.segments = []
    if "processing" not in st.session_state:
        st.session_state.processing = False
    if "selected_step" not in st.session_state:
        st.session_state.selected_step = 0
    if "current_project_id" not in st.session_state:
        st.session_state.current_project_id = None
    if "current_project_name" not in st.session_state:
        st.session_state.current_project_name = ""
    if "video_filename" not in st.session_state:
        st.session_state.video_filename = ""
    if "is_audio_only" not in st.session_state:
        st.session_state.is_audio_only = False
    if "groq_api_key" not in st.session_state:
        st.session_state.groq_api_key = ""
    if "gemini_api_key" not in st.session_state:
        st.session_state.gemini_api_key = ""
    if "whisper_model" not in st.session_state:
        st.session_state.whisper_model = "whisper-large-v3"
    if "supabase_url" not in st.session_state:
        st.session_state.supabase_url = ""
    if "supabase_key" not in st.session_state:
        st.session_state.supabase_key = ""

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        # ============================================
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        # ============================================
        st.header("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ")

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¸€è¦§ã‚’å–å¾—
        projects = get_project_list()

        # æ–°è¦ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä½œæˆãƒœã‚¿ãƒ³
        if st.button("â• æ–°è¦ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ", use_container_width=True):
            st.session_state.current_project_id = None
            st.session_state.current_project_name = ""
            st.session_state.steps = []
            st.session_state.flow_summary = None
            st.session_state.video_path = None
            st.session_state.video_duration = 0
            st.session_state.segments = []
            st.session_state.video_filename = ""
            st.session_state.is_audio_only = False
            st.rerun()

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¸€è¦§è¡¨ç¤º
        if projects:
            st.caption(f"ä¿å­˜æ¸ˆã¿: {len(projects)}ä»¶")

            for proj in projects:
                col1, col2 = st.columns([4, 1])
                with col1:
                    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé¸æŠãƒœã‚¿ãƒ³
                    is_current = (st.session_state.current_project_id == proj["id"])
                    button_label = f"{'ğŸ“‚ ' if is_current else 'ğŸ“ '}{proj['name'][:20]}"
                    if st.button(button_label, key=f"proj_{proj['id']}", use_container_width=True):
                        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’èª­ã¿è¾¼ã¿
                        data = load_project(proj["id"])
                        if data:
                            st.session_state.current_project_id = proj["id"]
                            st.session_state.current_project_name = data.get("name", "")
                            st.session_state.steps = data.get("steps", [])
                            st.session_state.flow_summary = data.get("flow_summary")
                            st.session_state.segments = data.get("segments", [])
                            st.session_state.video_duration = data.get("video_duration", 0)
                            st.session_state.video_filename = data.get("video_name", "")
                            st.session_state.video_path = None  # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã¯å†èª­ã¿è¾¼ã¿å¿…è¦
                            st.rerun()
                with col2:
                    # å‰Šé™¤ãƒœã‚¿ãƒ³
                    if st.button("ğŸ—‘", key=f"del_{proj['id']}", help="å‰Šé™¤"):
                        delete_project(proj["id"])
                        if st.session_state.current_project_id == proj["id"]:
                            st.session_state.current_project_id = None
                            st.session_state.current_project_name = ""
                            st.session_state.steps = []
                            st.session_state.flow_summary = None
                        st.rerun()
        else:
            st.caption("ä¿å­˜ã•ã‚ŒãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“")

        st.divider()

        # ============================================
        # è¨­å®šã‚»ã‚¯ã‚·ãƒ§ãƒ³
        # ============================================
        st.header("APIè¨­å®š")

        # secrets.tomlã®ãƒ‘ã‚¹
        secrets_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), ".streamlit", "secrets.toml")

        # ä¿å­˜æ¸ˆã¿ã®å€¤ã‚’èª­ã¿è¾¼ã¿
        def load_saved_secrets():
            saved = {}
            if os.path.exists(secrets_path):
                try:
                    with open(secrets_path, "r") as f:
                        for line in f:
                            line = line.strip()
                            if "=" in line and not line.startswith("#"):
                                key, val = line.split("=", 1)
                                saved[key.strip()] = val.strip().strip('"')
                except:
                    pass
            return saved

        saved_secrets = load_saved_secrets()
        default_groq_key = saved_secrets.get("GROQ_API_KEY", "")
        default_gemini_key = saved_secrets.get("GEMINI_API_KEY", "")
        default_supabase_url = saved_secrets.get("SUPABASE_URL", "")
        default_supabase_key = saved_secrets.get("SUPABASE_KEY", "")

        groq_api_key = st.text_input(
            "Groq API Key",
            value=default_groq_key,
            type="password",
            help="https://console.groq.com/ ã§APIã‚­ãƒ¼ã‚’å–å¾—ï¼ˆç„¡æ–™ï¼‰"
        )

        gemini_api_key = st.text_input(
            "Gemini API Key",
            value=default_gemini_key,
            type="password",
            help="Google AI Studioã§APIã‚­ãƒ¼ã‚’å–å¾—ã—ã¦ãã ã•ã„"
        )

        with st.expander("ã‚¯ãƒ©ã‚¦ãƒ‰ä¿å­˜è¨­å®šï¼ˆSupabaseï¼‰"):
            supabase_url = st.text_input(
                "Supabase URL",
                value=default_supabase_url,
                help="Supabaseãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã® URL"
            )
            supabase_key = st.text_input(
                "Supabase Anon Key",
                value=default_supabase_key,
                type="password",
                help="Supabaseã® anon/public ã‚­ãƒ¼"
            )

            # session_stateã«ä¿å­˜
            if supabase_url:
                st.session_state.supabase_url = supabase_url
            if supabase_key:
                st.session_state.supabase_key = supabase_key

            if supabase_url and supabase_key:
                st.success("Supabaseæ¥ç¶šæ¸ˆã¿")
            else:
                st.info("Supabaseã‚’è¨­å®šã™ã‚‹ã¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒã‚¯ãƒ©ã‚¦ãƒ‰ã«ä¿å­˜ã•ã‚Œã¾ã™")

        # APIã‚­ãƒ¼ä¿å­˜ãƒœã‚¿ãƒ³ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã®ã¿æœ‰åŠ¹ï¼‰
        is_cloud = os.environ.get("STREAMLIT_SHARING_MODE") or os.path.exists("/mount/src")
        if is_cloud:
            st.info("ã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒã§ã¯Streamlit Cloudã®Secretsã§ç®¡ç†ã•ã‚Œã¦ã„ã¾ã™")
        else:
            if st.button("APIã‚­ãƒ¼ã‚’ä¿å­˜", use_container_width=True):
                try:
                    os.makedirs(os.path.dirname(secrets_path), exist_ok=True)
                    with open(secrets_path, "w") as f:
                        if groq_api_key:
                            f.write(f'GROQ_API_KEY = "{groq_api_key}"\n')
                        if gemini_api_key:
                            f.write(f'GEMINI_API_KEY = "{gemini_api_key}"\n')
                        if supabase_url:
                            f.write(f'SUPABASE_URL = "{supabase_url}"\n')
                        if supabase_key:
                            f.write(f'SUPABASE_KEY = "{supabase_key}"\n')
                    st.success("ä¿å­˜ã—ã¾ã—ãŸï¼æ¬¡å›ã‹ã‚‰è‡ªå‹•å…¥åŠ›ã•ã‚Œã¾ã™")
                except Exception as e:
                    st.error(f"ä¿å­˜ã«å¤±æ•—: {str(e)}")

        whisper_model = st.selectbox(
            "Whisperãƒ¢ãƒ‡ãƒ«",
            options=["whisper-large-v3", "whisper-large-v3-turbo"],
            index=0,
            help="large-v3: æœ€é«˜ç²¾åº¦ / large-v3-turbo: é«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆ",
            format_func=lambda x: "Whisper large-v3ï¼ˆæœ€é«˜ç²¾åº¦ï¼‰" if x == "whisper-large-v3" else "Whisper large-v3 Turboï¼ˆé«˜é€Ÿï¼‰"
        )

        st.divider()

        st.caption(f"éŸ³å£°èªè­˜: Groq {whisper_model}")
        st.caption(f"ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ: {GEMINI_MODEL_PRO}")

        st.divider()

        # ============================================
        # å‹•ç”»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        # ============================================
        st.header("ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")

        uploaded_file = st.file_uploader(
            "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=None,
            help="MP4ï¼ˆå‹•ç”»ï¼‰ã¾ãŸã¯MP3ï¼ˆéŸ³å£°ï¼‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆå¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã¯è‡ªå‹•åˆ†å‰²ã•ã‚Œã¾ã™ï¼‰"
        )

        if uploaded_file is not None:
            # ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ãƒã‚§ãƒƒã‚¯
            file_ext = os.path.splitext(uploaded_file.name)[1].lower()
            if file_ext not in [".mp4", ".mp3"]:
                st.error("MP4ã¾ãŸã¯MP3ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
                uploaded_file = None

        if uploaded_file is not None:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºè¡¨ç¤º
            file_size_mb = uploaded_file.size / (1024 * 1024)
            st.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size_mb:.1f} MB")

            if file_size_mb > MAX_CHUNK_SIZE_MB:
                st.warning(f"å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã§ã™ã€‚{MAX_CHUNK_SIZE_MB}MBä»¥ä¸‹ã«è‡ªå‹•åˆ†å‰²ã—ã¦å‡¦ç†ã—ã¾ã™ã€‚")

            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
            is_audio = uploaded_file.name.lower().endswith(".mp3")
            file_suffix = ".mp3" if is_audio else ".mp4"
            with tempfile.NamedTemporaryFile(delete=False, suffix=file_suffix) as tmp:
                tmp.write(uploaded_file.read())
                st.session_state.video_path = tmp.name
                st.session_state.is_audio_only = is_audio
                if is_audio:
                    st.session_state.video_duration = get_audio_duration(tmp.name)
                else:
                    st.session_state.video_duration = get_video_duration(tmp.name)
                st.session_state.video_filename = uploaded_file.name

            if st.button("è§£æé–‹å§‹", type="primary", use_container_width=True):
                if not groq_api_key:
                    st.error("Groq API Keyã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                elif not gemini_api_key:
                    st.error("Gemini API Keyã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                else:
                    # æ–°ã—ã„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDã‚’ç”Ÿæˆ
                    st.session_state.current_project_id = generate_project_id()
                    st.session_state.current_project_name = os.path.splitext(uploaded_file.name)[0]
                    st.session_state.processing = True
                    st.session_state.groq_api_key = groq_api_key
                    st.session_state.gemini_api_key = gemini_api_key
                    st.session_state.whisper_model = whisper_model

    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ã®ã‚¿ã‚¤ãƒˆãƒ«
    if st.session_state.current_project_name:
        st.title(f"ğŸ“‹ {st.session_state.current_project_name}")
    else:
        st.title("æ¥­å‹™ãƒãƒ‹ãƒ¥ã‚¢ãƒ«è‡ªå‹•ç”Ÿæˆã‚¢ãƒ—ãƒª")

    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    if st.session_state.processing and st.session_state.video_path:
        with st.spinner("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æä¸­..."):
            progress = st.progress(0)
            status = st.empty()

            # ã€Stage 1-Aã€‘éŸ³å£°èªè­˜ï¼ˆMP3ã¯ç›´æ¥å‡¦ç†ã€MP4ã¯éŸ³å£°æŠ½å‡ºå¾Œã«å‡¦ç†ï¼‰
            if st.session_state.is_audio_only:
                all_segments = transcribe_audio_file(
                    audio_path=st.session_state.video_path,
                    groq_api_key=st.session_state.groq_api_key,
                    whisper_model=st.session_state.whisper_model,
                    progress_callback=lambda p: progress.progress(p),
                    status_callback=lambda s: status.text(s)
                )
            else:
                all_segments = transcribe_full_video(
                    video_path=st.session_state.video_path,
                    groq_api_key=st.session_state.groq_api_key,
                    whisper_model=st.session_state.whisper_model,
                    progress_callback=lambda p: progress.progress(p),
                    status_callback=lambda s: status.text(s)
                )

            st.session_state.segments = all_segments

            # ã€Stage 1-Bã€‘ãƒ•ãƒ«ã‚³ãƒ³ãƒ†ã‚¯ã‚¹ãƒˆã‚’Gemini Proã«æ¸¡ã—ã¦ã‚¢ã‚¯ã‚·ãƒ§ãƒ³åˆ—ã‚’ç”Ÿæˆ
            status.text("AIãŒæ¥­å‹™ãƒ•ãƒ­ãƒ¼ã‚’åˆ†æä¸­...")
            progress.progress(45)

            full_transcript = build_full_transcript(all_segments)

            if not full_transcript.strip():
                st.warning("éŸ³å£°ãŒèªè­˜ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã«éŸ³å£°ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                st.session_state.steps = []
                st.session_state.flow_summary = None
                st.session_state.processing = False
                st.rerun()

            # Gemini Pro ã§ãƒ•ãƒ«ã‚³ãƒ³ãƒ†ã‚¯ã‚¹ãƒˆè§£æ
            print(f"[DEBUG] æ–‡å­—èµ·ã“ã—ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°: {len(all_segments)}")
            print(f"[DEBUG] æ–‡å­—èµ·ã“ã—æ–‡å­—æ•°: {len(full_transcript)}")
            gemini_result = analyze_full_context_with_gemini(st.session_state.gemini_api_key, full_transcript)

            if gemini_result is None:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šã‚»ã‚°ãƒ¡ãƒ³ãƒˆå˜ä½ã§ç°¡æ˜“ã‚¹ãƒ†ãƒƒãƒ—ã‚’ç”Ÿæˆ
                status.text("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ä¸­...")
                progress.progress(70)
                print("[DEBUG] Geminiè§£æå¤±æ•— â†’ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†")

                st.warning("AIè§£æã«å¤±æ•—ã—ãŸãŸã‚ã€ç°¡æ˜“ãªæ‰‹é †ã‚’ç”Ÿæˆã—ã¾ã™ã€‚")
                steps = generate_fallback_steps(all_segments, st.session_state.video_path)
                st.session_state.flow_summary = None
            else:
                flow_summary = gemini_result.get("flow_summary", "")
                actions = gemini_result.get("actions", [])
                print(f"[DEBUG] Geminiè§£ææˆåŠŸ: flow_summaryé•·={len(flow_summary)}, actionsæ•°={len(actions)}")

                st.session_state.flow_summary = flow_summary

                # ã€Stage 2-Aã€‘ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«ãƒãƒƒãƒ”ãƒ³ã‚°
                status.text("ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã¨æ˜ åƒã‚’ãƒãƒƒãƒ”ãƒ³ã‚°ä¸­...")
                progress.progress(60)

                mapped_actions = map_actions_to_segments(actions, all_segments)

                # ã€Stage 2-Bã€‘ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’å–å¾—ï¼ˆå‹•ç”»ã®å ´åˆã®ã¿ï¼‰
                if not st.session_state.is_audio_only:
                    status.text("ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’å–å¾—ä¸­...")
                    progress.progress(80)
                    steps = extract_screenshots_for_actions(st.session_state.video_path, mapped_actions)
                else:
                    progress.progress(80)
                    steps = mapped_actions

            st.session_state.steps = steps

            progress.progress(95)
            status.text("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ä¿å­˜ä¸­...")

            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’è‡ªå‹•ä¿å­˜
            if st.session_state.current_project_id:
                save_project(
                    project_id=st.session_state.current_project_id,
                    name=st.session_state.current_project_name,
                    video_name=st.session_state.video_filename,
                    steps=st.session_state.steps,
                    flow_summary=st.session_state.flow_summary,
                    segments=st.session_state.segments,
                    video_duration=st.session_state.video_duration
                )

            progress.progress(100)
            status.text("å®Œäº†!")

            st.session_state.processing = False
            st.rerun()

    # ã‚¨ãƒ‡ã‚£ã‚¿UI
    if st.session_state.steps:
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåç·¨é›†ã¨ä¿å­˜ãƒœã‚¿ãƒ³
        proj_col1, proj_col2, proj_col3 = st.columns([3, 1, 1])
        with proj_col1:
            new_project_name = st.text_input(
                "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå",
                value=st.session_state.current_project_name,
                key="project_name_input",
                label_visibility="collapsed",
                placeholder="ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã‚’å…¥åŠ›..."
            )
            if new_project_name != st.session_state.current_project_name:
                st.session_state.current_project_name = new_project_name
        with proj_col2:
            if st.button("ğŸ’¾ ä¿å­˜", use_container_width=True, type="primary"):
                if st.session_state.current_project_id:
                    save_project(
                        project_id=st.session_state.current_project_id,
                        name=st.session_state.current_project_name,
                        video_name=st.session_state.video_filename,
                        steps=st.session_state.steps,
                        flow_summary=st.session_state.flow_summary,
                        segments=st.session_state.segments,
                        video_duration=st.session_state.video_duration
                    )
                    st.success("ä¿å­˜ã—ã¾ã—ãŸï¼")
                else:
                    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDãŒãªã„å ´åˆã¯æ–°è¦ä½œæˆ
                    st.session_state.current_project_id = generate_project_id()
                    save_project(
                        project_id=st.session_state.current_project_id,
                        name=st.session_state.current_project_name or "ç„¡é¡Œã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ",
                        video_name=st.session_state.video_filename,
                        steps=st.session_state.steps,
                        flow_summary=st.session_state.flow_summary,
                        segments=st.session_state.segments,
                        video_duration=st.session_state.video_duration
                    )
                    st.success("æ–°è¦ä¿å­˜ã—ã¾ã—ãŸï¼")
                    st.rerun()
        with proj_col3:
            st.caption(f"ID: {st.session_state.current_project_id or 'æœªä¿å­˜'}")

        # ãƒ•ãƒ­ãƒ¼æ¦‚è¦ã‚’è¡¨ç¤º
        if st.session_state.flow_summary:
            st.info(f"**æ¥­å‹™ãƒ•ãƒ­ãƒ¼æ¦‚è¦:** {st.session_state.flow_summary}")

        col_left, col_right = st.columns([1.5, 1])

        # å³ã‚«ãƒ©ãƒ : ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ & ãƒ„ãƒ¼ãƒ«
        with col_right:
            if not st.session_state.get("is_audio_only", False):
                st.subheader("å‹•ç”»ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")

                if st.session_state.video_path and os.path.exists(st.session_state.video_path):
                    st.video(st.session_state.video_path)

                st.divider()

                st.subheader("ç”»åƒå–å¾—ãƒ„ãƒ¼ãƒ«")

                capture_time = st.slider(
                    "ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼ˆç§’ï¼‰",
                    min_value=0.0,
                    max_value=float(max(1, int(st.session_state.video_duration))),
                    value=0.0,
                    step=0.5,
                    key="capture_slider"
                )

                target_step = st.selectbox(
                    "é©ç”¨å…ˆã®æ‰‹é †",
                    options=range(len(st.session_state.steps)),
                    format_func=lambda x: f"{st.session_state.steps[x].get('index', x+1)}. {st.session_state.steps[x]['action_title']}" if not st.session_state.steps[x].get("deleted") else f"{x+1}. (å‰Šé™¤æ¸ˆã¿)",
                    key="target_step_select"
                )

                if st.button("ã“ã®ç¬é–“ã®ç”»åƒã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£", use_container_width=True):
                    if st.session_state.video_path:
                        new_frame = extract_frame(st.session_state.video_path, capture_time)
                        if new_frame is not None:
                            st.session_state.steps[target_step]["image"] = new_frame
                            st.session_state.steps[target_step]["timestamp"] = format_timestamp(capture_time)
                            st.session_state.steps[target_step]["timestamp_seconds"] = capture_time
                            st.success("ç”»åƒã‚’æ›´æ–°ã—ã¾ã—ãŸ")
                            st.rerun()
                        else:
                            st.error("ãƒ•ãƒ¬ãƒ¼ãƒ ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            else:
                st.subheader("éŸ³å£°ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
                if st.session_state.video_path and os.path.exists(st.session_state.video_path):
                    st.audio(st.session_state.video_path)
                st.info("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãŸã‚ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆå–å¾—ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“")

        # å·¦ã‚«ãƒ©ãƒ : ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã‚¨ãƒ‡ã‚£ã‚¿
        with col_left:
            st.subheader("ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ç·¨é›†")

            for i, step in enumerate(st.session_state.steps):
                if step.get("deleted", False):
                    continue

                with st.container():
                    importance_badge = "ğŸ”´ " if step.get("is_important") or step.get("importance") == "high" else ""
                    st.markdown(f"### {importance_badge}æ‰‹é † {step.get('index', i+1)}: {step['timestamp']}")

                    col_img, col_edit = st.columns([1, 2])

                    with col_img:
                        if step.get("image") is not None:
                            st.image(step["image"], use_container_width=True)
                            if st.button("ç”»åƒã‚’å‰Šé™¤", key=f"del_img_{i}"):
                                st.session_state.steps[i]["image"] = None
                                st.rerun()
                        else:
                            st.info("ç”»åƒãªã—")

                    with col_edit:
                        new_title = st.text_input(
                            "ã‚¿ã‚¤ãƒˆãƒ«",
                            value=step["action_title"],
                            key=f"title_{i}"
                        )
                        st.session_state.steps[i]["action_title"] = new_title

                        # è©³ç´°æƒ…å ±ï¼ˆactor, screen, object, operationï¼‰ã‚’è¡¨ç¤º
                        detail_cols = st.columns(2)
                        with detail_cols[0]:
                            if step.get("actor"):
                                st.caption(f"æ‹…å½“: {step['actor']}")
                            if step.get("screen"):
                                st.caption(f"ç”»é¢: {step['screen']}")
                        with detail_cols[1]:
                            if step.get("object"):
                                st.caption(f"å¯¾è±¡: {step['object']}")
                            if step.get("operation"):
                                st.caption(f"æ“ä½œ: {step['operation']}")

                        new_desc = st.text_area(
                            "èª¬æ˜",
                            value=step["description"],
                            key=f"desc_{i}",
                            height=100
                        )
                        st.session_state.steps[i]["description"] = new_desc

                        if step.get("ai_hypothesis"):
                            hypothesis = step['ai_hypothesis']
                            # ã€æƒ…å ±ä¸è¶³ã€‘ã‚„ã€è¦ç¢ºèªã€‘ã‚’å¼·èª¿è¡¨ç¤º
                            if "ã€æƒ…å ±ä¸è¶³ã€‘" in hypothesis:
                                st.error(f"æƒ…å ±ä¸è¶³: {hypothesis}")
                            elif "ã€è¦ç¢ºèªã€‘" in hypothesis:
                                st.warning(f"è¦ç¢ºèª: {hypothesis}")
                            elif step.get("is_important") or step.get("importance") == "high":
                                st.warning(f"AIä»®èª¬: {hypothesis}")
                            else:
                                st.info(f"AIä»®èª¬: {hypothesis}")

                            resolved = st.checkbox(
                                "è§£æ±ºæ¸ˆã¿",
                                value=step.get("hypothesis_resolved", False),
                                key=f"resolved_{i}"
                            )
                            st.session_state.steps[i]["hypothesis_resolved"] = resolved

                        if st.button("ã“ã®æ‰‹é †ã‚’å‰Šé™¤", key=f"del_step_{i}"):
                            st.session_state.steps[i]["deleted"] = True
                            st.rerun()

                    st.divider()

            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            st.subheader("å‡ºåŠ›")

            # å‡ºåŠ›å½¢å¼ã®é¸æŠ
            output_format = st.radio(
                "å‡ºåŠ›å½¢å¼",
                options=["Word (.docx)", "Markdown (.md)"],
                horizontal=True,
                key="output_format"
            )

            if output_format == "Word (.docx)":
                if DOCX_AVAILABLE:
                    if st.button("Wordãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ", type="primary", use_container_width=True):
                        word_data = generate_word_document(
                            st.session_state.steps,
                            st.session_state.flow_summary
                        )
                        if word_data:
                            st.download_button(
                                label="Wordãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (.docx)",
                                data=word_data,
                                file_name="manual.docx",
                                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                                use_container_width=True
                            )
                        else:
                            st.error("Wordæ–‡æ›¸ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                else:
                    st.warning("python-docxãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`pip install python-docx`ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            else:
                if st.button("Markdownã‚’ç”Ÿæˆ", type="primary", use_container_width=True):
                    markdown, images = generate_markdown(
                        st.session_state.steps,
                        st.session_state.flow_summary
                    )
                    zip_data = create_download_zip(markdown, images)

                    st.download_button(
                        label="ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (.md + ç”»åƒ)",
                        data=zip_data,
                        file_name="manual.zip",
                        mime="application/zip",
                        use_container_width=True
                    )

    elif not st.session_state.processing:
        st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦è§£æã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")

        with st.expander("ä½¿ã„æ–¹"):
            st.markdown("""
            ### åŸºæœ¬çš„ãªä½¿ã„æ–¹
            1. **ã‚µã‚¤ãƒ‰ãƒãƒ¼**ã§Gemini API Keyã‚’å…¥åŠ›
            2. å¿…è¦ã«å¿œã˜ã¦Whisperãƒ¢ãƒ‡ãƒ«ã‚’èª¿æ•´
            3. MP4å‹•ç”»ã¾ãŸã¯MP3éŸ³å£°ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            4. ã€Œè§£æé–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
            5. ç”Ÿæˆã•ã‚ŒãŸãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã‚’ç·¨é›†
            6. Word ã¾ãŸã¯ Markdown ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

            ### ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†
            - **è‡ªå‹•ä¿å­˜**: è§£æå®Œäº†å¾Œã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯è‡ªå‹•çš„ã«ä¿å­˜ã•ã‚Œã¾ã™
            - **æ‰‹å‹•ä¿å­˜**: ç·¨é›†å¾Œã¯ã€ŒğŸ’¾ ä¿å­˜ã€ãƒœã‚¿ãƒ³ã§ä¿å­˜ã§ãã¾ã™
            - **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ‡ã‚Šæ›¿ãˆ**: ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ğŸ“ã‚¢ã‚¤ã‚³ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã§åˆ‡ã‚Šæ›¿ãˆ
            - **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå‰Šé™¤**: ğŸ—‘ã‚¢ã‚¤ã‚³ãƒ³ã§å‰Šé™¤
            - **æ–°è¦ä½œæˆ**: ã€Œâ• æ–°è¦ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã€ãƒœã‚¿ãƒ³ã§æ–°ã—ã„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é–‹å§‹

            ### å‡¦ç†æ–¹å¼
            - **Stage 1**: å‹•ç”»å…¨ä½“ã®æ–‡å­—èµ·ã“ã—ã‚’AIï¼ˆGemini Proï¼‰ã«æ¸¡ã—ã€æ¥­å‹™ãƒ•ãƒ­ãƒ¼å…¨ä½“ã‚’ç†è§£ã•ã›ã¾ã™
            - **Stage 2**: AIãŒç”Ÿæˆã—ãŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³åˆ—ã«å¯¾ã—ã¦ã€é©åˆ‡ãªã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’è‡ªå‹•ãƒãƒƒãƒ”ãƒ³ã‚°ã—ã¾ã™

            ã“ã‚Œã«ã‚ˆã‚Šã€å¾“æ¥ã®ã€Œã¶ã¤åˆ‡ã‚Šã€ãªèª¬æ˜ã§ã¯ãªãã€**æ–‡è„ˆã‚’è¸ã¾ãˆãŸå®Œçµã—ãŸèª¬æ˜æ–‡**ãŒç”Ÿæˆã•ã‚Œã¾ã™ã€‚

            ### å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã«ã¤ã„ã¦
            100MBã‚’è¶…ãˆã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã¯è‡ªå‹•çš„ã«åˆ†å‰²ã—ã¦å‡¦ç†ã•ã‚Œã€çµæœãŒçµ±åˆã•ã‚Œã¾ã™ã€‚
            """)


if __name__ == "__main__":
    main()
